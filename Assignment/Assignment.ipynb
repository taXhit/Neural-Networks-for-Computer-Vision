{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "RksWtNuHg9Rb"
   },
   "source": [
    "# Final Assignment - Neural Networks for Computer Vision\n",
    "*  In this assignment, we will build a classifier for MNIST from scratch using just [NumPy](https://numpy.org/)\n",
    "\n",
    "*  [MNIST](http://yann.lecun.com/exdb/mnist/) dataset contains images of handwritten digits of size 28x28\n",
    "\n",
    "*  The dataset that you are expected to use for training can be found [here](https://drive.google.com/file/d/1DF-OWSP803x34FrvaJ4XeDm_QZUevu32/view?usp=sharing)\n",
    "\n",
    "*   Our model will have 1 hidden layer, like the one below (not our recommendation to use 256 in the hidden layer though, try various values out)\n",
    "\n",
    "**Feel free to redefine any function signatures below, just make sure the final cell remains the same.**\n",
    "\n",
    "<center>\n",
    "<img src=\"https://user-images.githubusercontent.com/81357954/166119893-4ca347b8-b1a4-40b8-9e0a-2e92b5f164ae.png\">\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "UyOAG55siwdI"
   },
   "source": [
    "## Import libraries here\n",
    "NumPy, Matplotlib, ...\n",
    "\n",
    "Also remember to initialize the seed for reproducibility of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7iVUsRLxjAb9"
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HaLDC4wN0eQs"
   },
   "source": [
    "## Load *Dataset*\n",
    "Load data from the given pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qOjNSmx0iUn"
   },
   "outputs": [],
   "source": [
    "# mount Google Drive to access the dataset\n",
    "\n",
    "# load the data set\n",
    "\n",
    "X = pass\n",
    "y = pass\n",
    "\n",
    "# normalize\n",
    "\n",
    "# Split into X_train, y_train, X_test, y_test\n",
    "# you can use stratified splitting from sklearn library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "id77Oqc90kTf"
   },
   "outputs": [],
   "source": [
    "# display a 4x4 grid, \n",
    "# choose 16 images randomly, display the images as well as corresponding labels\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "VFYnsPVLmsiW"
   },
   "source": [
    "## Building up parts of our classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wAsGtgxUpGh2"
   },
   "source": [
    "**Activation functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Di5Ck47msCQ"
   },
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    z -- A scalar or numpy array.\n",
    "    Return:\n",
    "    relu func applied to each element of z\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def softmax(z):\n",
    "    \"\"\"\n",
    "    returns computed probabilitites for each element in batch separately\n",
    "    input: (N, 10)\n",
    "    output: (N, 10)\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "G-q5HJHIocdn"
   },
   "source": [
    "**Notes about the Neural Network** \n",
    "*   Input size is (784,) because 28x28 = 784\n",
    "*   Output size will be 10, each element represeting probability of the image representing that digit\n",
    "*   Size of the hidden layer is a hyperparameter\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "azTAuS5spFcz"
   },
   "source": [
    "**Initialize the layers weights**\n",
    "\n",
    "Generally, we follow the convention that weights are drawn from a standard normal distribution, while the bias vectors are initialized to zero. But you can try everything out :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38E3_hVPocMm"
   },
   "outputs": [],
   "source": [
    "def init_params(\"\"\"TO DO\"\"\"):\n",
    "    \"\"\"\n",
    "    ideally it should take the size of all the layers and \n",
    "    should return the initialized weights.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "UlX8zy-7pv2n"
   },
   "source": [
    "**Forward Propagation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJ8lgrqjjASz"
   },
   "outputs": [],
   "source": [
    "def forward_propg(X, weights):\n",
    "    \"\"\"\n",
    "    X: input data\n",
    "    returns: logits, output of each layer z1,z2,a1,a2\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "asZmbRVvuy5x"
   },
   "source": [
    "**Backward Propagation**\n",
    "\n",
    "\n",
    "You may use stochastic gradient descent or batch gradient descent here. Feel free to use any loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kAmrTAlimjUN"
   },
   "outputs": [],
   "source": [
    "def backward_propg(weights, X, y, \"\"\"output of forward propg\"\"\"):\n",
    "    \"\"\"\n",
    "    should update the weights and return updated weights\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVDz0IGnvzpe"
   },
   "outputs": [],
   "source": [
    "def cost_func(weight,y,params):\n",
    "    \"\"\"\n",
    "    calculate loss to check whether it is decreasing at each epoch or not\n",
    "    one can return this in backward propagation as well\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "GUlhpcs9ylOX"
   },
   "source": [
    "\n",
    "## Integrate everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SDGdT7PVmjRU"
   },
   "outputs": [],
   "source": [
    "def train(X, y, hidden_nodes, epochs=1000, lr=1e-5):\n",
    "    \"\"\"\n",
    "    hidden_nodes: no. of nodes in hidden layer\n",
    "\n",
    "    should return the updated optimize weights.\n",
    "    \"\"\"\n",
    "    # initialize weights.\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # forward propagation\n",
    "\n",
    "        # print cost at every 100 or so iterations\n",
    "        \n",
    "        # backward propagation\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9XBinWpPmjOS"
   },
   "outputs": [],
   "source": [
    "def predict(X, updated_weights):\n",
    "    \"\"\"\n",
    "    returns the prediction in [0,9] for each element in X\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CtKSZWw71wc4"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, y):\n",
    "    \"\"\"\n",
    "    prints % accuracy\n",
    "    \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "fGVOZ8yg0VrV"
   },
   "source": [
    "### Save as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "_lvDVwmxmjKX",
    "outputId": "02467c3f-b20f-44b7-8e3d-43e308028d17"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "from google.colab import files\n",
    "\n",
    "roll_num = \"_________\" # enter ldap\n",
    "hidden_dim = pass # replace with your own hidden dimension\n",
    "\n",
    "model_dict = {\n",
    "    'z': hidden_dim, # hidden dimension of your model\n",
    "    'layer_0_wt': pass, # layer 0 weight (784, z)\n",
    "    'layer_0_bias': pass, # layer 0 bias (z, 1)\n",
    "    'layer_1_wt': pass, # layer 1 weight (z, 10)\n",
    "    'layer_1_bias': pass # layer 1 bias (10, 1)\n",
    "}\n",
    "\n",
    "assert model_dict['layer_0_wt'].shape == (784, hidden_dim)\n",
    "assert model_dict['layer_0_bias'].shape == (hidden_dim, 1)\n",
    "assert model_dict['layer_1_wt'].shape == (hidden_dim, 10)\n",
    "assert model_dict['layer_1_bias'].shape == (10, 1)\n",
    "\n",
    "with open(f'model_{roll_num}.pkl', 'wb') as f:\n",
    "    pickle.dump(model_dict, f)\n",
    "    files.download(f'model_{roll_num}.pkl') # download the file from the Colab session for submission"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN-lytical Assignment-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
